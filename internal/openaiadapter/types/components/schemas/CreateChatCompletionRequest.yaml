allOf:
  - $ref: CreateModelResponseProperties.yaml
  - type: object
    properties:
      messages:
        type: array
        items:
          $ref: ./ChatCompletionRequestMessage.yaml
        minItems: 1

      model:
        type: string

      modalities:
        $ref: ../../openai/openai.yaml#/components/schemas/ResponseModalities

      verbosity:
        type: string
        nullable: true
        enum:
          - low
          - medium
          - high
        default: medium

      reasoning_effort:
        $ref: ../../openai/openai.yaml#/components/schemas/ReasoningEffort

      max_completion_tokens:
        type: integer
        nullable: true

      frequency_penalty:
        type: number
        default: 0
        minimum: -2
        maximum: 2
        nullable: true

      presence_penalty:
        type: number
        default: 0
        minimum: -2
        maximum: 2
        nullable: true

      web_search_options:
        properties:
          user_location:
            type: object
            nullable: true
            required:
              - type
              - approximate
            properties:
              type:
                type: string
                enum:
                  - approximate
              approximate:
                $ref: ../../openai/openai.yaml#/components/schemas/WebSearchLocation
          search_context_size:
            $ref: ../../openai/openai.yaml#/components/schemas/WebSearchContextSize

      top_logprobs:
        type: integer
        minimum: 0
        maximum: 20
        nullable: true

      response_format:
        anyOf:
          - $ref: ../../openai/openai.yaml#/components/schemas/ResponseFormatText
          - $ref: ../../openai/openai.yaml#/components/schemas/ResponseFormatJsonSchema
          - $ref: ../../openai/openai.yaml#/components/schemas/ResponseFormatJsonObject
        discriminator:
          propertyName: type
          mapping:
            text: ../../openai/openai.yaml#/components/schemas/ResponseFormatText
            json_schema: ../../openai/openai.yaml#/components/schemas/ResponseFormatJsonSchema
            json_object: ../../openai/openai.yaml#/components/schemas/ResponseFormatJsonObject

      audio:
        type: object
        nullable: true
        required:
          - voice
          - format
        properties:
          voice:
            $ref: ../../openai/openai.yaml#/components/schemas/VoiceIdsShared
          format:
            type: string
            enum:
              - wav
              - aac
              - mp3
              - flac
              - opus
              - pcm16

      store:
        type: boolean
        description: >-
          Whether or not to store the output of this chat completion request for
          use in our [model distillation](https://platform.openai.com/docs/guides/distillation) or
          [evals](https://platform.openai.com/docs/guides/evals) products.

          Supports text and image inputs. Note: image inputs over 8MB will be dropped.
        default: false
        nullable: true

      stream:
        type: boolean
        nullable: true
        default: false

      stop:
        $ref: ../../openai/openai.yaml#/components/schemas/StopConfiguration

      logit_bias:
        type: object
        description: >-
                Modify the likelihood of specified tokens appearing in the completion.

                Accepts a JSON object that maps tokens (specified by their token ID in the
                tokenizer) to an associated bias value from -100 to 100. Mathematically,
                the bias is added to the logits generated by the model prior to sampling.
                The exact effect will vary per model, but values between -1 and 1 should
                decrease or increase likelihood of selection; values like -100 or 100
                should result in a ban or exclusive selection of the relevant token.
        default: null
        nullable: true
        additionalProperties:
          type: integer

      logprobs:
        type: boolean
        default: false
        nullable: true

      max_tokens:
        type: integer
        nullable: true
        deprecated: true
        x-deprecated-reason: 'Use `max_completion_tokens`'

      n:
        type: integer
        minimum: 1
        maximum: 128
        default: 1
        example: 1
        nullable: true

      prediction:
        anyOf:
          - $ref: ../../openai/openai.yaml#/components/schemas/PredictionContent
        nullable: true
        discriminator:
          propertyName: type
          mapping:
            content: ../../openai/openai.yaml#/components/schemas/PredictionContent

      seed:
        type: integer
        minimum: -9223372036854776000
        maximum: 9223372036854776000
        nullable: true

      stream_options:
        $ref: ../../openai/openai.yaml#/components/schemas/ChatCompletionStreamOptions

      tools:
        type: array
        items:
          anyOf:
            - $ref: ../../openai/openai.yaml#/components/schemas/ChatCompletionTool
            - $ref: CustomToolChatCompletions.yaml
          discriminator:
            propertyName: type
            mapping:
              function: ../../openai/openai.yaml#/components/schemas/ChatCompletionTool
              custom: CustomToolChatCompletions.yaml

      tool_choice:
        $ref: ChatCompletionToolChoiceOption.yaml

      parallel_tool_calls:
        $ref: ../../openai/openai.yaml#/components/schemas/ParallelToolCalls

      function_call:
        deprecated: true
        x-deprecated-reason: Use `tool_choice`
        description: |-
          Deprecated in favor of `tool_choice`. Controls which (if any) function
          is called by the model.

          - `none` means the model will not call a function and instead generates a
          message.
          - `auto` means the model can pick between generating a message or calling a
          function.

          Specifying a particular function via `{"name": "my_function"}` forces
          the model to call that function. `none` is the default when no
          functions are present. `auto` is the default if functions are present.
        anyOf:
          - type: string
            description: >-
              `none` means the model will not call a function and instead generates a message.
              `auto` means the model can pick between generating a message or calling a function.
            enum:
              - none
              - auto
          - $ref: ../../openai/openai.yaml#/components/schemas/ChatCompletionFunctionCallOption

      functions:
        deprecated: true
        x-deprecated-reason: Use `tools`
        description: >-
          Deprecated in favor of `tools`. A list of functions the model may
          generate JSON inputs for.
        type: array
        minItems: 1
        maxItems: 128
        items:
          $ref: ../../openai/openai.yaml#/components/schemas/ChatCompletionFunctions

      extra_body:
        description: >-
          Extra parameters to add to the request body. Will be merged.
        type: object
        additionalProperties: true

    required:
      - messages
      - model
